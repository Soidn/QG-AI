#### **概念**： 

[Keras（一种用 Python 编写的神经网络 API](https://deeplizard.com/course/tfcpailzrd)）



机器学习（Machine Learning）（使用算法分析数据，**从数据中学习**，然后对新数据做出确定或预测的做法。）



深度学习（机器学习的一个子领域，它使用受大脑神经网络结构和功能启发的算法。）



人工神经网络（ANN / Artificial Neural Network ）/ net（网络）/ neural net（神经网络）/  model （模型）：一种计算系统，它由一组称为神经元的连接单元组成，这些单元被组织成我们所说的层。

  结构：

1. Input layer （输入层） - 输入数据的每个组件对应一个节点。

2. Hidden layer（隐藏层 ）- 任意的节点数。

3. Output layer （输出层） - 每个可能的所需输出对应一个节点。

   

深度网络/深度人工神经网络（深度学习使用的一种特定类型的 ANN）



神经元/节点（Neuron/Node）：神经网络中的基本处理单元，负责接收输入、执行计算并传递输出。对应特征维度



特征值（Feature Value）：样本（Sample）在某个特征维度（Feature Dimension）上的具体数值



不同的层对其输入执行不同的转换

- 密集层/全连接层（Dense layer/ Fully Connected layer）（每个节点都连接到下一层中的**所有**节点，完全连接每个输入到其层中的每个输出）
- 卷积层（通常用于处理图像数据的模型）
- 循环层（用于处理时间序列数据的模型）



图层权重（Weight）（表示两个节点之间的连接强度）：两个节点之间的每个连接都有。当网络在输入层的给定节点收到输入时，输入乘以权重分配给各个连接，再通过连接传递到下一个节点，最后，下一层中的节点计算每个传入连接的加权和，将此总和传递给激活函数，执行某种类型的转换后输出节点。



**激活函数**（Activation Function）对神经元输入的加权和（weighted sum of the inputs）进行处理，从而确定神经元的输出（output），将总和转换为介于某个下限和某个上限之间的数字，通常是非线性转换，为神经网络引入了非线性特性，使得神经网络能够学习和表示复杂的函数关系）

`relu` （Rectified Linear Unit / 修正线性单元）：如果输入是正数，就直接输出这个正数；如果输入是负数，就输出 0。

`softmax` 是一种特殊的激活函数，它主要用于多分类问题。它会把输出层每个节点的输出值转换为概率值，并且这些概率值的总和为 1。

**Sigmoid** ：将输入压缩到 (0, 1)区间，适合二分类任务，负输入接近0，正输入接近1。公式为
$$
\sigma(x) = \frac{1}{1 + e^{-x}}
$$


通过网络的前向传播（forward pass）：对于数据集中的给定样本，从输入层到输出层的整个过程

反向传播（backpropagation）：计算各层损失对权重的梯度，为梯度下降提供更新参数所需的梯度信息



一个 epoch （轮次）：模型将所有训练数据**完整处理一遍的过程**，即每个样本都参与一次前向传播和反向传播。



批次（Batch）：将数据拆分为小单元（如每批 32、64 个样本），每次仅处理少量数据，大幅降低内存占用，使训练在普通硬件上也能运行。按批次训练也便于监控训练状态。



学习率（Learning Rate）（学习率是优化器（optimizer）的核心参数之一。决定向最小值方向迈出的步长，通常介于 0.01 到 0.0001 之间，太小会导致收敛速度慢，太大会导致模型无法收敛或在最优解附近震荡。）
$$
新权重 = 旧权重 - （学习率 * 梯度）
$$
超参数是机器学习中，在模型训练前由人工设定，无法通过数据训练直接学习得到的参数。





**梯度（gradient）**：多元函数的导数，梯度的方向指向损失函数在该点增长最快的方向，因此参数更新方向与梯度方向**相反**（即梯度下降）



训练（training）：反复将数据输入模型进行前向传播得到预测结果，计算损失函数值，再通过反向传播算法计算梯度，根据梯度对模型参数进行更新，如此循环迭代，直至模型达到较好的性能。



训练模型（通过优化算法优化模型中的权重）



为了模型的训练和测试，将数据分解为三个不同的数据集。这些数据集包括：

- 训练集（Training set）：每个 epoch 中，模型将反复使用训练集中的相同数据进行训练
- 验证集（Validation set）：独立于训练集，用于在训练期间验证模型，检查模型的泛化程度。此过程可能提供有助于调整超参数的信息。
- 测试集（Test set）：用于在模型训练后测试模型，测试模型的最终泛化能力。区别是测试集不被标记，而训练集和验证集必须进行标记



推理（inference）：使用训练好的模型对新数据进行预测



优化算法（Optimization Algorithm）/**优化器（ optimizer ）**

- 梯度下降算法： 参数更新公式为：
  $$
  \theta = \theta - \eta \cdot \nabla L(\theta)
  $$
   *θ*是参数，*η*是学习率， ∇*L*(*θ*)是损失函数对参数的梯度。

-   随机梯度下降（Stochastic Gradient Descent / SGD）：更新模型权重，达成优化目标，即最小化损失函数，每次只随机选取一个训练样本计算梯度并更新参数。

  



损失（模型预测结果与真实结果之间的差异）



**损失函数（Loss Function）**（将模型预测值和真实值映射为一个非负实数的函数）

回归问题：

- 均方误差（Mean Squared Error / MSE，属于 L2 损失函数 ）和平均绝对误差（Mean Absolute Error / MAE，属于 L1 损失函数），它们度量模型估计值与观测值之间的差异。例如预测房屋价。MSE 会对预测值和真实价格差值进行平方计算，放大误差，对较大的偏差给予更大惩罚；MAE 则是取差值的绝对值，对异常值更具鲁棒性。

- $$
  \text{MSE} = \frac{1}{m} \sum_{i=1}^m (\hat{y}_i - y_i)^2
  $$

- $$
  \text{MAE} = \frac{1}{m} \sum_{i=1}^m |\hat{y}_i - y_i|\
  $$

  



分类问题：

常用 0 - 1 损失、交叉熵损失函数等。

0 - 1 损失直接衡量分类是否正确，分类正确为 0，错误为 1，但不利于求解优化问题，常使用其代理损失函数，如交叉熵损失函数。交叉熵损失函数本质是信息理论中的交叉熵在分类问题中的应用，在 logistic 回归、人工神经网络等分类器中广泛使用。

交叉熵：
$$
L = -\frac{1}{m} \sum_{i=1}^m y_i \log \hat{y}_i
$$


模型“学习” 过程

1. 当模型初始化时，网络权重会被设置为**随机值**

2. 获得输出后，通过比较模型预测值与真实标签，选择**损失函数**计算该特定输出的**损失（或误差）**

3. 计算损失后，针对网络中的每个权重计算该损失函数的**梯度**

4. 用获得梯度值来**更新模型的权重**。梯度会指示使损失向最小值移动的方向，而我们的任务是沿着降低损失的方向调整权重，逐步接近这个最小值。

5. 将梯度值乘以一个称为**学习率**的参数，然后从当前权重中减去这个乘积，得到更新后的权重值。

     

   （ 每当数据通过网络时，模型中的**每个权重都会经历相同的更新过程**，梯度是针对每个权重单独计算的 ）



标签（Label）是数据的真实结果（如分类任务中的类别、回归任务中的数值），常用于监督学习，模型通过学习输入数据与标签之间的关系，调整内部参数（如权重、偏差），最终建立输入到输出的映射函数 
$$
f(x) \approx y
$$






#### **理解**：

- 每个样本由多个特征值构成

- 特征维度数等于输入层节点数

- 每个特征值属于特定的特征维度

```plaintext
样本 → 包含多个特征值 → 每个特征值对应一个特征维度 → 特征维度映射到输入层节点
```

**输出层神经元数量取决于任务类型：**

- **分类任务**
  - **二分类任务**：通常输出层只设置 1 个神经元，使用 `sigmoid` 激活函数，输出值在 0 到 1 之间，表示属于某一类别的概率。例如，判断一张图片是猫还是狗，输出值接近 0 表示是猫的概率大，接近 1 表示是狗的概率大。
  - **多分类任务**：输出层神经元的数量就等于类别的数量。使用 `softmax` 激活函数，将输出转换为每个类别的概率分布。
- **回归任务**：如果是回归任务，输出层神经元的数量通常为 1，用于输出一个连续的数值。例如，预测房价，输出层就只需要 1 个神经元输出预测的房价数值。

输出取决于网络内每个连接的权重。

损失函数是随机梯度下降（SGD）试图通过迭代更新网络内权重来最小化的对象。

训练过程中，若数据以批次形式传递给网络，模型会针对每个批次的数据计算损失值

使用优化器时，需为优化器设置学习率，优化器再基于该学习率更新模型参数。







## Keras

Sequential 模型（线性的 SequenceStack（顺序栈)，一种线性堆叠模型，允许按顺序添加不同的层 ）

Dense（全连接层）ANN 中最基本的层类型，每个输出都是使用该层的每个输入计算的。

激活函数（一种非线性函数，在结构或顺序上跟在密集层（对输入数据进行线性变换）之后，对密集层的输出进行非线性变换。）



### 使用 Keras 构建简单顺序模型的步骤

#### 1. 导入所需的 Keras 类

在开始构建模型之前，需要导入 Keras 中的相关类。以下代码导入了`Sequential`模型和`Dense`层以及`Activation`模块：

```python
from keras.models import Sequential
from keras.layers import Dense, Activation
```

- `from keras.models import Sequential`：从 Keras 中导入 `Sequential` 模型类。`Sequential` 模型是一种线性堆叠模型，允许按顺序依次添加各层。
- `from keras.layers import Activation`：导入激活函数层，激活函数为神经网络引入非线性因素，使网络能够学习更复杂的模式。

#### 2. 创建 Sequential 模型实例

接下来，我们要创建一个`Sequential`模型的实例。`Sequential`模型是一种线性堆叠模型，允许我们按顺序添加不同的层。在创建实例时，需要传递一个层对象的数组。

```python
layers = [
    Dense(units=6, input_shape=(8,), activation='relu'),  # 第一个隐藏层及输入层信息
    Dense(units=6, activation='relu'),
    Dense(units=4, activation='softmax')  # 通过数组中最后定义的 Dense 层来确定输出层
]

model = Sequential(layers)  # 将 layers 列表传递给 Sequential 模型构造函数
```

- **units**：传递给`Dense`层构造函数的第一个参数`units`，表示该层应该有多少个神经元。例如`units=6`表示该层有 6 个神经元。
- **input_shape**：用于指定**输入层**的神经元数量。例子中，`input_shape=(8,)`表示输入层有 8个神经元。
- **activation**：指定激活函数。激活函数是一种非线性函数，通常紧跟在密集层之后。在我们的代码中，使用了两种激活函数：
  - `'relu'`：ReLU（Rectified Linear Unit）：引入非线性特性，有助于模型学习复杂的模式。
  - `'softmax'`：Softmax 函数：通常用于多分类问题的输出层，它能将输出转换为概率分布。





### 使用 Keras 训练模型的步骤

#### 1.导入所需的类

```python
import keras
from keras.models import Sequential
from keras.layers import Activation
from keras.layers.core import Dense
from keras.optimizers import Adam
from keras.metrics import categorical_crossentropy
```

- `from keras.layers.core import Dense`：导入全连接层（密集层）。全连接层是神经网络中最基本的层类型，每个神经元与上一层的所有神经元相连。
- `from keras.optimizers import Adam`：导入 Adam 优化器。Adam 是一种常用的优化算法，，能够自适应地调整每个参数的学习率。
- `from keras.metrics import categorical_crossentropy`：导入分类交叉熵损失函数。分类交叉熵常用于多分类问题，衡量模型预测的概率分布与真实标签之间的差异。

#### 2.定义模型

```python
model = Sequential([
    Dense(units=16, input_shape=(1,), activation='relu'),
    Dense(units=32, activation='relu'),
    Dense(units=2, activation='sigmoid')
])
```

#### 3.编译模型

```python
model.compile(
    optimizer=Adam(learning_rate=0.0001), 
    loss='sparse_categorical_crossentropy', 
    metrics=['accuracy']
)
```

- 在 `compile()` 函数中，传入了优化器、损失函数以及我们希望查看的评估指标。
- 优化器是 `Adam`，它是随机梯度下降（SGD）的一种变体。
- `loss='sparse_categorical_crossentropy'`：指定损失函数为稀疏分类交叉熵。当标签是整数编码时，使用 `sparse_categorical_crossentropy`；如果标签是 one - hot 编码，则使用 `categorical_crossentropy`。
- `metrics=['accuracy']`：指定评估指标为准确率。

#### 4.将模型与数据进行拟合（在数据上训练模型）

```python
model.fit(
    x=scaled_train_samples,   # 指定训练数据
    y=train_labels,  # 指定训练数据对应的标签
    batch_size=10, 
    epochs=20, 
    shuffle=True, 
    verbose=2
)
```

- `scaled_train_samples` 是一个由训练样本组成的 NumPy 数组。
- `train_labels` 是一个由训练样本对应**标签**组成的 NumPy 数组。
- `batch_size=10` 指定了每次应向模型输入多少个训练样本，以此数据会被分成多个批次。
- `epochs=20` 表示整个训练集（所有样本）将总共传递给模型 20 次。
- `shuffle=True` 表示在将数据传递给模型之前，应先对数据进行打乱。
- `verbose=2` 指定训练过程中日志信息的显示级别。`verbose=0` 表示不显示日志信息；`verbose=1` 表示显示进度条；`verbose=2` 表示每个 epoch 显示一行日志信息。